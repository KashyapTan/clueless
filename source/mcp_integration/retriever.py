import os
import sys
import numpy as np
import ollama
from typing import List, Dict, Any, Optional

try:
    from sentence_transformers import SentenceTransformer

    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    SentenceTransformer = None


class ToolRetriever:
    """
    Semantic retriever for MCP tools.

    Dynamically selects relevant tools based on user query similarity
    to tool descriptions.
    """

    def __init__(self):
        self._tool_embeddings: Dict[str, np.ndarray] = {}
        self._embedding_model_type = "unknown"  # "ollama" or "sentence-transformers"
        self._st_model = None
        self._ollama_model_name = "nomic-embed-text"
        self._check_embedding_backend()

    def _check_embedding_backend(self):
        """Determine which embedding backend to use."""
        # 1. Try Ollama
        try:
            # Simple check if ollama is reachable and model exists
            models_response = ollama.list()

            model_list: List[Any] = []
            if hasattr(models_response, "models"):
                model_list = list(models_response.models)
            elif isinstance(models_response, dict) and "models" in models_response:
                model_list = list(models_response["models"])
            elif isinstance(models_response, list):
                model_list = models_response
            else:
                # Fallback: single object or unknown format, wrap in list
                model_list = [models_response]

            model_names = []
            for m in model_list:
                # Handle both object attribute access and dictionary key access
                # Use Any to bypass strict type checking on the loop variable
                model_obj: Any = m
                if hasattr(model_obj, "model"):
                    model_names.append(model_obj.model)
                elif isinstance(model_obj, dict):
                    # Some versions use 'name', some use 'model'
                    model_names.append(model_obj.get("model") or model_obj.get("name"))
                else:
                    # Last resort string conversion
                    model_names.append(str(model_obj))

            # Check for exact match or match with tag
            # We look for "nomic-embed-text" or similar embedding models
            target_substrings = ["nomic-embed-text", "all-minilm", "mxbai-embed-large"]
            found_model = None

            for model_name in model_names:
                for target in target_substrings:
                    if target in model_name:
                        found_model = model_name
                        break
                if found_model:
                    break

            if found_model:
                self._embedding_model_type = "ollama"
                self._ollama_model_name = found_model
                print(
                    f"[ToolRetriever] Using Ollama embedding model: {self._ollama_model_name}"
                )
                return
        except Exception as e:
            print(f"[ToolRetriever] Ollama check failed: {e}")

        # 2. Fallback to SentenceTransformers
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            self._embedding_model_type = "sentence-transformers"
            print("[ToolRetriever] Using sentence-transformers (all-MiniLM-L6-v2)")
            # Load lazily in embed_text to avoid startup delay if not needed
        else:
            print(
                "[ToolRetriever] WARNING: No embedding backend available. Retrieval will return all tools."
            )
            self._embedding_model_type = "none"

    def _get_embedding(self, text: str) -> np.ndarray:
        """Get embedding for a single string."""
        if self._embedding_model_type == "ollama":
            try:
                response = ollama.embeddings(model=self._ollama_model_name, prompt=text)
                return np.array(response["embedding"])
            except Exception as e:
                print(f"[ToolRetriever] Ollama embedding failed: {e}")
                return np.zeros(1)  # Fail safe

        elif self._embedding_model_type == "sentence-transformers":
            if (
                self._st_model is None
                and SENTENCE_TRANSFORMERS_AVAILABLE
                and SentenceTransformer
            ):
                print("[ToolRetriever] Loading sentence-transformers model...")
                self._st_model = SentenceTransformer("all-MiniLM-L6-v2")  # type: ignore

            if self._st_model:
                # Ensure we return a numpy array, handling potential Tensor output
                embedding = self._st_model.encode(text)
                if isinstance(embedding, np.ndarray):
                    return embedding
                return np.array(embedding)

        return np.zeros(1)

    def embed_tools(self, tools: List[Dict]):
        """
        Embed tool descriptions and cache them.

        Args:
            tools: List of tool definitions (Ollama format or similar dicts
                   with 'function' -> 'name', 'description')
        """
        if self._embedding_model_type == "none":
            return

        print(f"[ToolRetriever] Embedding {len(tools)} tools...")
        self._tool_embeddings.clear()

        for tool in tools:
            # Handle different tool formats if necessary, assuming Ollama format for now
            # {'type': 'function', 'function': {'name': '...', 'description': '...'}}

            func = tool.get("function", {})
            name = func.get("name")
            description = func.get("description", "")

            if not name:
                continue

            # Combine name and description for better semantic match
            text_to_embed = f"{name}: {description}"
            embedding = self._get_embedding(text_to_embed)
            self._tool_embeddings[name] = embedding

        print("[ToolRetriever] Tool embedding complete.")

    def retrieve_tools(
        self, query: str, all_tools: List[Dict], always_on: List[str], top_k: int = 5
    ) -> List[Dict]:
        """
        Select relevant tools for the query.

        Args:
            query: User's chat message
            all_tools: Full list of available tools
            always_on: List of tool names to always include
            top_k: Number of semantic matches to include

        Returns:
            Filtered list of tool definitions
        """
        # 1. Identify always-on tools
        selected_tool_names = set(always_on)

        # 2. Semantic retrieval
        if top_k > 0 and self._embedding_model_type != "none" and query.strip() and self._tool_embeddings:
            query_embedding = self._get_embedding(query)

            scores = []
            for name, embedding in self._tool_embeddings.items():
                if name in selected_tool_names:
                    continue  # Already selected

                if embedding.shape != query_embedding.shape:
                    continue

                # Cosine similarity
                norm_q = np.linalg.norm(query_embedding)
                norm_t = np.linalg.norm(embedding)

                if norm_q == 0 or norm_t == 0:
                    sim = 0
                else:
                    sim = np.dot(query_embedding, embedding) / (norm_q * norm_t)

                scores.append((sim, name))

            # Sort by similarity desc
            scores.sort(key=lambda x: x[0], reverse=True)

            # Pick top K
            for _, name in scores[:top_k]:
                selected_tool_names.add(name)

        # 3. Filter the full tool list
        final_tools = [
            t
            for t in all_tools
            if t.get("function", {}).get("name") in selected_tool_names
        ]

        print(f"[ToolRetriever] Query: '{query}'")
        print(
            f"[ToolRetriever] Selected {len(final_tools)} tools out of {len(all_tools)} available."
        )
        for t in final_tools:
            print(f" - {t.get('function', {}).get('name')}")

        return final_tools


# Global instance
retriever = ToolRetriever()
